@misc{ModulePytorc,
  file = {Module \textemdash{} PyTorch 2.6 documentation:/home/michal\_atlas/Zotero/storage/8USNAZY4/torch.nn.Module.html:text/html},
  title = {Module \textemdash{} PyTorch 2.6 documentation},
  url = {https://pytorch.org/docs/stable/generated/torch.nn.Module.html},
  urldate = {2025-02-17},
}

@misc{NxpImxTflite,
  file = {nxp-imx/tflite-vx-delegate-imx at lf-6.6.23\_2.0.0:/home/michal\_atlas/Zotero/storage/M4GGRYZ2/lf-6.6.23\_2.0.html:text/html},
  title = {nxp-imx/tflite-vx-delegate-imx at lf-6.6.23\_2.0.0},
  url = {https://github.com/nxp-imx/tflite-vx-delegate-imx/tree/lf-6.6.23\_2.0.0},
  urldate = {2024-10-25},
}

@misc{EnArmTqma8mpx,
  file = {en\textbackslash{}:arm\textbackslash{}:tqma8mpxl\textbackslash{}:linux\textbackslash{}:yocto\textbackslash{}:overview \vert{} TQ Support Wiki:/home/michal\_atlas/Zotero/storage/UDSV6233/overview.html:text/html},
  title = {en:arm:tqma8mpxl:linux:yocto:overview \textbackslash{}textbar TQ Support Wiki},
  url = {https://support.tq-group.com/en/arm/tqma8mpxl/linux/yocto/overview},
  urldate = {2025-01-02},
}

@misc{EnArmTqma8mpx,
  file = {en\textbackslash{}:arm\textbackslash{}:tqma8mpxl\textbackslash{}:linux\textbackslash{}:yocto\textbackslash{}:quickstart\_yocto \vert{} TQ Support Wiki:/home/michal\_atlas/Zotero/storage/C2ZZPX46/quickstart\_yocto.html:text/html},
  title = {en:arm:tqma8mpxl:linux:yocto:quickstart\_yocto \textbackslash{}textbar TQ Support Wiki},
  url = {https://support.tq-group.com/en/arm/tqma8mpxl/linux/yocto/quickstart\_yocto},
  urldate = {2025-01-02},
}

@article{IMx8mPlusAp,
  file = {PDF:/home/michal\_atlas/Zotero/storage/RWYF8SQK/i.MX 8M Plus Applications Processor Reference Manual.pdf:application/pdf},
  language = {en},
  title = {i.MX 8M Plus Applications Processor Reference Manual},
}

@article{PyTorchQuant,
  title = {PyTorch documentation - Quantization},
  url = {https://pytorch.org/docs/stable/quantization.html},
}

@article{AN12964,
  title = {i.MX 8M Plus NPU Warmup Time},
  url = {https://www.mouser.com/pdfDocs/AN12964.pdf},
}

@misc{WikiONNX,
  title = {Open Neural Network Exchange - Wikipedia},
  url = {https://en.wikipedia.org/wiki/Open\_Neural\_Network\_Exchange},
}

@misc{OnnxConcepts,
  file = {ONNX Concepts - ONNX 1.18.0 documentation:/home/michal\_atlas/Zotero/storage/YD63AHV5/concepts.html:text/html},
  title = {ONNX Concepts - ONNX 1.18.0 documentation},
  url = {https://onnx.ai/onnx/intro/concepts.html},
  urldate = {2025-02-17},
}

@article{HowToUseOpen,
  abstract = {This guide is about how to use EVIS to create user nodes and kernels in~OpenVX to implement image processing on NPU(i.MX8MP)/GPU(i.MX8QM). Take gaussian filter as an example. It is tested on i.MX8QM and i.MX8MP.  User Node Creation from User Kernel 1. Define a user node Register a user kernel by its...},
  title = {How to use OpenVX extension for NPU/GPU to accelerate machine vision applications},
  url = {https://community.nxp.com/t5/i-MX-Processors-Knowledge-Base/How-to-use-OpenVX-extension-for-NPU-GPU-to-accelerate-machine/ta-p/1113429},
}

@misc{HDF5PY,
  title = {h5py: Manual},
  url = {https://docs.h5py.org/en/stable/quick.html},
}

@misc{AndroidNNAPI,
  title = {Neural Networks API \vert{} Android NDK \vert{} Android Developers},
  url = {https://developer.android.com/ndk/guides/neuralnetworks},
}

@misc{HowToUseOpen2020,
  abstract = {This guide is about how to use EVIS to create user nodes and kernels in~OpenVX to implement image processing on NPU(i.MX8MP)/GPU(i.MX8QM). Take gaussian filter as an example. It is tested on i.MX8QM and i.MX8MP.  User Node Creation from User Kernel 1. Define a user node Register a user kernel by its...},
  file = {Snapshot:/home/michal\_atlas/Zotero/storage/4TK9WIUU/1113429.html:text/html},
  journal = {NXP Community},
  language = {en},
  month = {February},
  note = {Section: i.MX Processors Knowledge Base},
  title = {How to use OpenVX extension for NPU/GPU to accelerate machine vision applications},
  url = {https://community.nxp.com/t5/i-MX-Processors-Knowledge-Base/How-to-use-OpenVX-extension-for-NPU-GPU-to-accelerate-machine/ta-p/1113429},
  urldate = {2024-10-27},
  year = {2020},
}

@article{OpenVXAMD,
  abstract = {MIVisionX API},
  keywords = {MIVisionX, ROCm, API, reference, data type, support},
  title = {AMD OpenVX documentation \vert{} ROCm\texttrademark{} Software Future Release},
  url = {https://rocm.docs.amd.com/projects/MIVisionX/en/develop/how-to/amd\_openvx.html},
}

@article{YoctoPackages,
  title = {Yocto Project Reference Manual \vert{} Required Packages for the Host Development System},
  url = {https://docs.yoctoproject.org/2.4/ref-manual/ref-manual.html\#detailed-supported-distros},
}

@misc{GithubNxpIm,
  abstract = {i.MX Release Manifest},
  title = {GitHub - nxp-imx/imx-manifest: i.MX Release Manifest},
  url = {https://github.com/nxp-imx/imx-manifest},
}

@misc{CoralEdgeTpuCompiler,
  abstract = {Use the Edge TPU Compiler to convert TensorFlow Lite models to a format compatible, with the Edge TPU.},
  title = {Edge TPU Compiler \vert{} Coral},
  url = {https://coral.ai/docs/edgetpu/compiler/},
}

@misc{OpenCVTimVxBackend,
  abstract = {Open Source Computer Vision Library. Contribute to opencv/opencv development by creating an account on GitHub.},
  title = {TIM VX Backend For Running OpenCV On NPU},
  url = {https://github.com/opencv/opencv/wiki/TIM-VX-Backend-For-Running-OpenCV-On-NPU},
}

@misc{YoctoBmap,
  abstract = {BMAP Tools an account on GitHub.},
  title = {GitHub - yoctoproject/bmaptool: BMAP Tools},
  url = {https://github.com/yoctoproject/bmaptool},
}

@misc{DeviceTensors,
  abstract = {Custom device memory usage to reduce copies},
  title = {Device tensors},
  url = {https://onnxruntime.ai/docs/performance/device-tensor.html},
}

@misc{KhronosgroupOp2024,
  abstract = {OpenVX sample implementation},
  month = {October},
  publisher = {The Khronos Group},
  title = {KhronosGroup/OpenVX-sample-impl},
  url = {https://github.com/KhronosGroup/OpenVX-sample-impl},
  urldate = {2024-10-25},
  year = {2024},
}

@misc{ExploitingPythHamann2020,
  abstract = {How unpickling untrusted data can lead to remote code execution.},
  author = {Hamann, David},
  file = {Snapshot:/home/michal\_atlas/Zotero/storage/ZQJ9592A/exploiting-python-pickle.html:text/html},
  journal = {David Hamann},
  language = {en},
  month = {April},
  title = {Exploiting Python pickles},
  url = {https://davidhamann.de/2020/04/05/exploiting-python-pickle/},
  urldate = {2024-10-25},
  year = {2020},
}

@misc{OpenvxPortab2011,
  abstract = {OpenVX\texttrademark{} is an open, royalty-free standard for cross platform acceleration of computer vision applications. OpenVX enables performance and power-optimized computer vision processing, especially important in embedded and real-time use cases such as face, body and gesture tracking, smart video surveillance, advanced driver assistance systems (ADAS), object and scene reconstruction, augmented reality, visual inspection, robotics and more.},
  file = {Snapshot:/home/michal\_atlas/Zotero/storage/WBWGQQ4U/openvx.html:text/html},
  journal = {The Khronos Group},
  language = {en},
  month = {December},
  note = {Section: API},
  title = {OpenVX - Portable, Power-efficient Vision Processing},
  url = {https://www.khronos.org/openvx/},
  urldate = {2024-10-25},
  year = {2011},
}

@article{ACrossPlatforDavila2022,
  abstract = {FPGAs are an excellent platform to implement computer vision applications, since these applications tend to offer a high level of parallelism with many data-independent operations. However, the freedom in the solution design space of FPGAs represents a problem because each solution must be individually designed, verified, and tuned. The emergence of High Level Synthesis (HLS) helps solving this problem and has allowed the implementation of open programming standards as OpenVX for computer vision applications on FPGAs, such as the HiFlipVX library developed exclusively for Xilinx devices. Although with the HiFlipVX library, designers can develop solutions efficiently on Xilinx, they do not have an approach to port and run their code on FPGAs from other manufacturers.},
  author = {D\'{a}vila-Guzm\'{a}n, Maria Ang\'{e}lica and Kalms, Lester and Gran Tejero, Rub\'{e}n and Villarroya-Gaud\'{o}, Mar\'{\i}a and Su\'{a}rez Gracia, Dar\'{\i}o and G\"{o}hringer, Diana},
  doi = {10.1016/j.sysarc.2021.102372},
  file = {PDF:/home/michal\_atlas/Zotero/storage/7G3K5BNM/D\'{a}vila-Guzm\'{a}n et al. - 2022 - A cross-platform OpenVX library for FPGA accelerators.pdf:application/pdf},
  issn = {13837621},
  journal = {Journal of Systems Architecture},
  language = {en},
  month = {February},
  pages = {102372},
  title = {A cross-platform OpenVX library for FPGA accelerators},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1383762121002575},
  urldate = {2024-10-30},
  volume = {123},
  year = {2022},
}

@misc{EnArmTqma8mpx,
  file = {en\textbackslash{}:arm\textbackslash{}:tqma8mpxl\textbackslash{}:linux\textbackslash{}:yocto\textbackslash{}:deployment\_yocto \vert{} TQ Support Wiki:/home/michal\_atlas/Zotero/storage/3ZIMSCYS/deployment\_yocto.html:text/html},
  title = {en:arm:tqma8mpxl:linux:yocto:deployment\_yocto \textbackslash{}textbar TQ Support Wiki},
  url = {https://support.tq-group.com/en/arm/tqma8mpxl/linux/yocto/deployment\_yocto},
  urldate = {2025-01-02},
}

@article{None,
  title = {None},
  url = {https://pytorch.org/tutorials/beginner/nn\_tutorial.html},
}

@article{IMx8mPlusAp,
  file = {PDF:/home/michal\_atlas/Zotero/storage/GY4FCICE/i.MX 8M Plus Applications Processor Datasheet for Industrial Products.pdf:application/pdf},
  language = {en},
  title = {i.MX 8M Plus Applications Processor Datasheet for Industrial Products},
}

@misc{VerisiliconTim2025,
  abstract = {VeriSilicon Tensor Interface Module},
  keywords = {deep-learning, neural-network, tensorflow},
  month = {January},
  publisher = {VeriSilicon Microelectronics (Shanghai) Co., Ltd.},
  title = {VeriSilicon/TIM-VX},
  url = {https://github.com/VeriSilicon/TIM-VX},
  year = {2025},
}

@article{IMxYoctoProjLfRe2024,
  abstract = {This document describes how to build an image for an i.MX board by using a Yocto Project build environment. It describes the i.MX release layer and i.MX-specific usage.},
  author = {Lf, Rev},
  file = {PDF:/home/michal\_atlas/Zotero/storage/GJA3GP2U/Lf - 2024 - i.MX Yocto Project User's Guide.pdf:application/pdf},
  language = {en},
  title = {i.MX Yocto Project User's Guide},
  year = {2024},
}

@misc{LitertOverview,
  title = {LiteRT overview - Google AI Edge},
  url = {https://ai.google.dev/edge/litert},
}

@misc{LoadingImages,
  abstract = {This page describes the process of using U-Boot to load Linux kernel and filesystem images from a TFTP server and save them to the local flash for use during the boot process.},
  file = {Snapshot:/home/michal\_atlas/Zotero/storage/CSMT5VTG/Loading\_Images\_with\_U-Boot.html:text/html},
  language = {en},
  title = {Loading Images with U-Boot - Loading Images with U-Boot},
  url = {https://wiki.emacinc.com/wiki/Loading\_Images\_with\_U-Boot},
  urldate = {2024-10-29},
}

@misc{Texasinstrument2024,
  abstract = {TI's implementation of the OpenVX standard.},
  month = {October},
  note = {original-date: 2023-06-02T20:18:18Z},
  publisher = {Texas Instruments},
  title = {TexasInstruments/tiovx},
  url = {https://github.com/TexasInstruments/tiovx},
  urldate = {2024-10-27},
  year = {2024},
}

@inproceedings{OpenvxGraphOpAbeysi2019,
  author = {Abeysinghe, Madushan and Villarreal, Jesse and Weaver, Lucas and Bakos, Jason},
  booktitle = {2019 IEEE 30th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
  doi = {10.1109/asap.2019.00-19},
  journal = {2019 IEEE 30th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
  month = {7},
  pages = {123--130},
  publisher = {IEEE},
  title = {OpenVX Graph Optimization for Visual Processor Units},
  url = {https://doi.org/10.1109/asap.2019.00-19},
  venue = {New York, NY, USA},
  year = {2019},
}

@misc{KerasWikiped,
  title = {Keras - Wikipedia},
  url = {https://en.wikipedia.org/wiki/Keras},
}

@misc{GoRepo,
  title = {repo - The Multiple Git Repository Tool},
  url = {https://gerrit.googlesource.com/git-repo},
}

@misc{NetronApp,
  abstract = {Visualizer for neural network, deep learning and machine learning models.},
  title = {Netron App},
  url = {https://netron.app/},
}

@misc{OpenVXNNE,
  title = {The OpenVX\texttrademark{} Neural Network Extension},
  url = {https://registry.khronos.org/OpenVX/extensions/vx\_khr\_nn/1.3/html/vx\_khr\_nn\_1\_3.html},
}

@misc{SupportedDevic,
  file = {Supported Devices, Chip Architectures, and Systems - Amazon SageMaker AI:/home/michal\_atlas/Zotero/storage/8BJWT86G/neo-supported-devices-edge-devices.html:text/html},
  title = {Supported Devices, Chip Architectures, and Systems - Amazon SageMaker AI},
  url = {https://docs.aws.amazon.com/sagemaker/latest/dg/neo-supported-devices-edge-devices.html},
  urldate = {2025-02-10},
}

@article{IMxMachineLeLfRe2024,
  abstract = {The NXP eIQ Machine Learning Software Development Environment (hereinafter referred to as "NXP eIQ") provides a set of libraries and development tools for machine learning applications targeting NXP microcontrollers and applications processors.},
  author = {Lf, Rev},
  file = {PDF:/home/michal\_atlas/Zotero/storage/HW4BIH4Y/Lf - 2024 - i.MX Machine Learning User's Guide.pdf:application/pdf},
  language = {en},
  title = {i.MX Machine Learning User's Guide},
  year = {2024},
}

@misc{NixEnvironment,
  abstract = {Repository to maintain out-of-tree shell.nix files (maintainer=@mic92) - nix-community/nix-environments},
  file = {Snapshot:/home/michal\_atlas/Zotero/storage/XDUZPFK7/shell.html:text/html},
  journal = {GitHub},
  language = {en},
  title = {nix-environments/envs/yocto/shell.nix at master \cdot{} nix-community/nix-environments},
  url = {https://github.com/nix-community/nix-environments/blob/master/envs/yocto/shell.nix},
  urldate = {2025-01-02},
}

@inproceedings{TheTheoryAndFellei1988,
  author = {Felleisen, M.},
  booktitle = {the 15th ACM SIGPLAN-SIGACT symposium},
  doi = {10.1145/73560.73576},
  journal = {Proceedings of the 15th ACM SIGPLAN-SIGACT symposium on Principles of programming languages  - POPL \textbackslash{}textquotesingle 88},
  month = {1},
  pages = {180--190},
  publisher = {ACM Press},
  title = {The theory and practice of first-class prompts},
  url = {https://doi.org/10.1145/73560.73576},
  venue = {San Diego, California, United States},
  year = {1988},
}

@misc{HttpsWwwTq,
  file = {https\textbackslash{}://www.tq-group.com/filedownloads/files/products/embedded/manuals/arm/carrierboard/MBa8MPxL/MBa8MPxL.UM.0103.pdf:/home/michal\_atlas/Zotero/storage/YWVBD4JM/MBa8MPxL.UM.0103.pdf:application/pdf;MBa8MPxL.UM.0103.pdf:/home/michal\_atlas/Zotero/storage/LN2CCE8R/MBa8MPxL.UM.0103.pdf:application/pdf},
  title = {https://www.tq-group.com/filedownloads/files/products/embedded/manuals/arm/carrierboard/MBa8MPxL/MBa8MPxL.UM.0103.pdf},
  url = {https://www.tq-group.com/filedownloads/files/products/embedded/manuals/arm/carrierboard/MBa8MPxL/MBa8MPxL.UM.0103.pdf},
  urldate = {2024-10-25},
}

@misc{OpenNeuralNet,
  file = {Open Neural Network Exchange Intermediate Representation (ONNX IR) Specification - ONNX 1.18.0 documentation:/home/michal\_atlas/Zotero/storage/FAE5X9W6/IR.html:text/html},
  title = {Open Neural Network Exchange Intermediate Representation (ONNX IR) Specification - ONNX 1.18.0 documentation},
  url = {https://onnx.ai/onnx/repo-docs/IR.html},
  urldate = {2025-02-17},
}

@article{HDF5FGGS,
  title = {The HDF5 Field Guide \vert{} Getting Started},
  url = {https://support.hdfgroup.org/documentation/hdf5/latest/\_intro\_h\_d\_f5.html},
}

@inproceedings{ExtendingTensoWang2022,
  abstract = {Deep-learning accelerators are increasingly popular. There are two prevalent accelerator architectures: one based on general matrix multiplication units and the other on convolution cores. However, Tensor Virtual Machine (TVM), a widely used deep-learning compiler stack, does not support the latter. This paper proposes a general framework for extending TVM to support deep-learning accelerators with convolution cores. We have applied it to two well-known accelerators: Nvidia's NVDLA and Bitmain's BM1880 successfully. Deep-learning workloads can now be readily deployed to these accelerators through TVM and executed efficiently. This framework can extend TVM to other accelerators with minimum effort.},
  author = {Wang, Yanzhao and Xie, Fei},
  booktitle = {2022 26th \lbrace{}International\rbrace{} \lbrace{}Conference\rbrace{} on \lbrace{}Engineering\rbrace{} of \lbrace{}Complex\rbrace{} \lbrace{}Computer\rbrace{} \lbrace{}Systems\rbrace{} (\lbrace{}ICECCS\rbrace{})},
  doi = {10.1109/ICECCS54210.2022.00031},
  file = {Full Text PDF:/home/michal\_atlas/Zotero/storage/C2TIBM5P/Wang and Xie - 2022 - Extending Tensor Virtual Machine to Support Deep-Learning Accelerators with Convolution Cores.pdf:application/pdf;IEEE Xplore Abstract Record:/home/michal\_atlas/Zotero/storage/WSCHXVMB/9763822.html:text/html},
  keywords = {Accelerator architectures, Application Software, Artificial Intelligence, Convolution, Open Source Software, Software, Software Architecture, Tensors, Virtual machining},
  month = {March},
  pages = {189--194},
  title = {Extending Tensor Virtual Machine to Support Deep-Learning Accelerators with Convolution Cores},
  url = {https://ieeexplore.ieee.org/document/9763822/?arnumber=9763822},
  urldate = {2025-02-17},
  year = {2022},
}

@misc{EnArmTqma8mpx,
  file = {en\textbackslash{}:arm\textbackslash{}:tqma8mpxl\textbackslash{}:linux\textbackslash{}:yocto\textbackslash{}:deployment\_yocto \vert{} TQ Support Wiki:/home/michal\_atlas/Zotero/storage/7X5V69NL/deployment\_yocto.html:text/html},
  title = {en:arm:tqma8mpxl:linux:yocto:deployment\_yocto \textbackslash{}textbar TQ Support Wiki},
  url = {https://support.tq-group.com/en/arm/tqma8mpxl/linux/yocto/deployment\_yocto},
  urldate = {2025-01-02},
}

@misc{GithubPaddle,
  abstract = {PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice （『飞桨』核心框架，深度学习\&机器学习高性能单机、分布式训练和跨平台部署） - PaddlePaddle/Paddle},
  title = {GitHub - PaddlePaddle/Paddle: PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice （『飞桨』核心框架，深度学习\&机器学习高性能单机、分布式训练和跨平台部署）},
  url = {https://github.com/PaddlePaddle/Paddle},
}

@misc{OpenvxVisionI2020,
  abstract = {Introduction EVIS (Enhanced Vision Instruction Set) is an API level program language, which is applicable~on GC7000XSVX (i.MX8QM) and VIP8000NanoSi (i.MX8MP). The instructions take advantage of the enhanced vision capabilities in the vision-capble hardware, with low-latency. It provides additional f...},
  file = {Snapshot:/home/michal\_atlas/Zotero/storage/PYX52FNL/1117280.html:text/html},
  journal = {NXP Community},
  language = {en},
  month = {February},
  note = {Section: i.MX Processors Knowledge Base},
  title = {OpenVX Vision Image Extension API Introduction - Basic API},
  url = {https://community.nxp.com/t5/i-MX-Processors-Knowledge-Base/OpenVX-Vision-Image-Extension-API-Introduction-Basic-API/ta-p/1117280},
  urldate = {2024-10-27},
  year = {2020},
}

@article{Zetane,
  title = {Zetane \vert{} Reliable AI automation for high-risk industries},
  url = {https://zetane.com/},
}

@article{ONNX,
  title = {ONNX},
  url = {https://onnx.ai/},
}

@article{IMxYoctoProjLfRe2024,
  abstract = {This document describes how to build an image for an i.MX board by using a Yocto Project build environment. It describes the i.MX release layer and i.MX-specific usage.},
  author = {Lf, Rev},
  file = {PDF:/home/michal\_atlas/Zotero/storage/GJA3GP2U/Lf - 2024 - i.MX Yocto Project User's Guide.pdf:application/pdf},
  language = {en},
  title = {i.MX Yocto Project User's Guide},
  year = {2024},
}

@article{IMxLinuxUserLfRe2024,
  abstract = {This document describes how to build and install the i.MX Linux OS BSP, where BSP stands for Board Support Package, on the i.MX platform. It also covers special i.MX features and how to use them.},
  author = {Lf, Rev},
  file = {PDF:/home/michal\_atlas/Zotero/storage/MVYHTGL3/Lf - 2024 - i.MX Linux User's Guide.pdf:application/pdf},
  language = {en},
  title = {i.MX Linux User's Guide},
  year = {2024},
}
